@article{agrawal2017cvqa,
  title   = {C-vqa: A compositional split of the visual question answering (vqa) v1. 0 dataset},
  author  = {Agrawal, Aishwarya and Kembhavi, Aniruddha and Batra, Dhruv and Parikh, Devi},
  journal = {arXiv preprint arXiv:1704.08243},
  year    = {2017}
}

@inproceedings{agrawal2018dont,
  author    = {Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
  title     = {Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {6},
  year      = {2018},
  pages     = {4971--4980}
}

@inproceedings{andreas2016neural,
  author    = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  title     = {Neural Module Networks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2016}
}

@inproceedings{antol2015vqa,
  author    = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C. and Parikh, Devi},
  title     = {VQA: Visual Question Answering},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month     = {12},
  year      = {2015}
}

@inproceedings{goyal2017making,
  author    = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  title     = {Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {6904--6913},
  month     = {7},
  year      = {2017}
}

@article{hudson2018compositional,
  author        = {Drew A. Hudson and
               Christopher D. Manning},
  title         = {Compositional Attention Networks for Machine Reasoning},
  journal       = {CoRR},
  volume        = {abs/1803.03067},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.03067},
  archiveprefix = {arXiv},
  eprint        = {1803.03067},
  timestamp     = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-03067.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hudson2019gqa,
  author    = {Hudson, Drew A. and Manning, Christopher D.},
  title     = {GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {6700--6709},
  year      = {2019}
}

@article{hudson2019gqa_preprint,
  author        = {Drew A. Hudson and
               Christopher D. Manning},
  title         = {{GQA:} a new dataset for compositional question answering over real-world
               images},
  journal       = {CoRR},
  volume        = {abs/1902.09506},
  year          = {2019},
  url           = {http://arxiv.org/abs/1902.09506},
  archiveprefix = {arXiv},
  eprint        = {1902.09506},
  timestamp     = {Tue, 21 May 2019 18:03:36 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1902-09506.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{johnson2017clevr,
  author    = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross},
  title     = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {2901--2910},
  month     = {7},
  year      = {2017}
}

@inproceedings{kafle2017analysis,
  author    = {Kafle, Kushal and Kanan, Christopher},
  title     = {An Analysis of Visual Question Answering Algorithms},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  pages     = {1965--1973},
  month     = {10},
  year      = {2017}
}

@article{krishna2017visual,
  title     = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations.(Article)},
  author    = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  issn      = {0920-5691},
  journal   = {International Journal of Computer Vision},
  volume    = {123},
  number    = {1},
  pages     = {32--73},
  year      = {2017},
  publisher = {Springer}
}

@inproceedings{lin2014microsoft,
  title        = {Microsoft coco: Common objects in context},
  author       = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle    = {European conference on computer vision},
  pages        = {740--755},
  year         = {2014},
  organization = {Springer}
}

@incollection{malinowski2014multiworld,
  title     = {A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input},
  author    = {Malinowski, Mateusz and Fritz, Mario},
  booktitle = {Advances in Neural Information Processing Systems 27},
  editor    = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
  pages     = {1682--1690},
  year      = {2014},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/5411-a-multi-world-approach-to-question-answering-about-real-world-scenes-based-on-uncertain-input.pdf}
}

@incollection{ren2015exploring,
  title     = {Exploring Models and Data for Image Question Answering},
  author    = {Ren, Mengye and Kiros, Ryan and Zemel, Richard},
  booktitle = {Advances in Neural Information Processing Systems 28},
  editor    = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
  pages     = {2953--2961},
  year      = {2015},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/5640-exploring-models-and-data-for-image-question-answering.pdf}
}

 @inproceedings{silberman2012indoor,
  title        = {Indoor segmentation and support inference from rgbd images},
  author       = {Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle    = {European conference on computer vision},
  pages        = {746--760},
  year         = {2012},
  organization = {Springer}
}

@article{thomee2016yfcc100m,
  author     = {Thomee, Bart and Shamma, David A. and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  title      = {YFCC100M: The New Data in Multimedia Research},
  year       = {2016},
  issue_date = {January 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {59},
  number     = {2},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/2812802},
  doi        = {10.1145/2812802},
  journal    = {Commun. ACM},
  month      = {0},
  pages      = {64â€“73},
  numpages   = {10}
}

@misc{wandb,
  title  = {Experiment Tracking with Weights and Biases},
  year   = {2020},
  note   = {Software available from wandb.com},
  url    = {https://www.wandb.com/},
  author = {Biewald, Lukas}
}

@inproceedings{yu2015visual,
  author    = {Yu, Licheng and Park, Eunbyung and Berg, Alexander C. and Berg, Tamara L.},
  title     = {Visual Madlibs: Fill in the Blank Description Generation and Question Answering},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month     = {12},
  year      = {2015},
  pages     = {2461--2469}
}

@inproceedings{zhang2016yin,
  author    = {Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  title     = {Yin and Yang: Balancing and Answering Binary Visual Questions},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {5014--5022},
  month     = {6},
  year      = {2016}
}

@inproceedings{zhu2016visual7w,
  author    = {Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  title     = {Visual7W: Grounded Question Answering in Images},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {4995--5004},
  month     = {6},
  year      = {2016}
}

@book{mohri2018foundations,
  title     = {Foundations of machine learning},
  author    = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year      = {2018},
  publisher = {MIT press}
}

@inproceedings{zitnick2013bringing,
  author    = {Zitnick, C. L. and Parikh, Devi},
  title     = {Bringing Semantics into Focus Using Visual Abstraction},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {6},
  year      = {2013}
}

@inproceedings{fey2019fast,
  title     = {Fast Graph Representation Learning with {PyTorch Geometric}},
  author    = {Fey, Matthias and Lenssen, Jan E.},
  booktitle = {ICLR Workshop on Representation Learning on Graphs and Manifolds},
  year      = {2019}
}

@inproceedings{eyzaguirre2020differentiable,
  title     = {Differentiable Adaptive Computation Time for Visual Reasoning},
  author    = {Eyzaguirre, Cristobal and Soto, Alvaro},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {6},
  pages     = {12817--12825},
  year      = {2020}
}

@incollection{paszke2019pytorch,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {8026--8037},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{wu1994verbs,
  author={Wu, Zhibiao and Palmer, Martha},
  title={Verbs Semantics and Lexical Selection},
  year={1994},
  publisher={Association for Computational Linguistics},
  address={USA},
  url={https://doi.org/10.3115/981732.981751},
  doi={10.3115/981732.981751},
  booktitle={Proceedings of the 32nd Annual Meeting on Association for Computational Linguistics},
  pages={133â€“138},
  numpages={6},
  location={Las Cruces, New Mexico},
  series={ACL â€™94}
}

@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={Communications of the ACM},
  volume={38},
  number={11},
  pages={39--41},
  year={1995},
  publisher={ACM New York, NY, USA}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@misc{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  url={http://yann.lecun.com/exdb/mnist/},
  year={1998}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{qi2017visual,
  abstract={<p>â€¢A comprehensive review of the state of the art on the emerging task of visual question answeringâ€¢Review the growing number of datasets, highlighting their distinct characteristicsâ€¢An in-depth analysis of the questions/answers provided in the recently-released Visual Genome dataset.</p> <p>Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer. In the first part of this survey, we examine the state of the art by comparing modern approaches to the problem. We classify methods by their mechanism to connect the visual and textual modalities. In particular, we examine the common approach of combining convolutional and recurrent neural networks to map images and questions to a common feature space. We...},
  author={Wu, Qi and Teney, Damien and Wang, Peng and Shen, Chunhua and Dick, Anthony and van Den Hengel, Anton},
  issn={1077-3142},
  journal={Computer Vision and Image Understanding},
  keywords={Visual Question Answering ; Natural Language Processing ; Knowledge Bases ; Recurrent Neural Networks ; Visual Question Answering ; Natural Language Processing ; Knowledge Bases ; Recurrent Neural Networks ; Engineering ; Applied Sciences ; Computer Science},
  language={eng},
  number={C},
  pages={21-40},
  publisher={Elsevier Inc},
  title={Visual question answering: A survey of methods and datasets},
  volume={163},
  year={2017},
}

@article{chen2015microsoft,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8317--8326},
  year={2019}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3608--3617},
  year={2018}
}

@inproceedings{gurari2019vizwiz,
  title={VizWiz-Priv: a dataset for recognizing the presence and purpose of private visual information in images taken by blind people},
  author={Gurari, Danna and Li, Qing and Lin, Chi and Zhao, Yinan and Guo, Anhong and Stangl, Abigale and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={939--948},
  year={2019}
}

@inproceedings{nema2018towards,
  title={Towards a Better Metric for Evaluating Question Generation Systems},
  author={Nema, Preksha and Khapra, Mitesh M},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3950--3959},
  year={2018}
}

@article{kafle2017visual,
  title={Visual question answering: Datasets, algorithms, and future challenges},
  author={Kafle, Kushal and Kanan, Christopher},
  journal={Computer Vision and Image Understanding},
  volume={163},
  pages={3--20},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{teney2018tips,
  title={Tips and tricks for visual question answering: Learnings from the 2017 challenge},
  author={Teney, Damien and Anderson, Peter and He, Xiaodong and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4223--4232},
  year={2018}
}

@inproceedings{malinowski2015ask,
  author = {Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
  title = {Ask Your Neurons: A Neural-Based Approach to Answering Questions About Images},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month = {December},
  pages={1--9},
  year = {2015}
}

@online{hudson2019evaluation_script,
  author = {Drew A. Hudson and
               Christopher D. Manning},
  title = {GQA Evaluation Script},
  year = 2019,
  url = {https://cs.stanford.edu/people/dorarad/gqa/evaluate.html},
  urldate = {2020-11-13}
}

@article{pearson1900x,
  title={X. On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume={50},
  number={302},
  pages={157--175},
  year={1900},
  publisher={Taylor \& Francis}
}

@inproceedings{ben2019block,
  title={Block: Bilinear superdiagonal fusion for visual question answering and visual relationship detection},
  author={Ben-Younes, Hedi and Cadene, Remi and Thome, Nicolas and Cord, Matthieu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={8102--8109},
  year={2019}
}

@inproceedings{ben2019block,
  title={Block: Bilinear superdiagonal fusion for visual question answering and visual relationship detection},
  author={Ben-Younes, Hedi and Cadene, Remi and Thome, Nicolas and Cord, Matthieu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={8102--8109},
  year={2019}
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}

@inproceedings{qi2020stanza,
 author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 title = {Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages},
 url = {https://nlp.stanford.edu/pubs/qi2020stanza.pdf},
 year = {2020}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{yang2018graph,
  title={Graph r-cnn for scene graph generation},
  author={Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={670--685},
  year={2018}
}
@inproceedings{li2019relation,
  title={Relation-aware graph attention network for visual question answering},
  author={Li, Linjie and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={10313--10322},
  year={2019}
}

@inproceedings{han2020victr,
    title = "{VICTR}: Visual Information Captured Text Representation for Text-to-Vision Multimodal Tasks",
    author = "Han, Caren  and
      Long, Siqu  and
      Luo, Siwen  and
      Wang, Kunze  and
      Poon, Josiah",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.coling-main.277",
    pages = "3107--3117",
    abstract = "Text-to-image multimodal tasks, generating/retrieving an image from a given text description, are extremely challenging tasks since raw text descriptions cover quite limited information in order to fully describe visually realistic images. We propose a new visual contextual text representation for text-to-image multimodal tasks, VICTR, which captures rich visual semantic information of objects from the text input. First, we use the text description as initial input and conduct dependency parsing to extract the syntactic structure and analyse the semantic aspect, including object quantities, to extract the scene graph. Then, we train the extracted objects, attributes, and relations in the scene graph and the corresponding geometric relation information using Graph Convolutional Networks, and it generates text representation which integrates textual and visual semantic information. The text representation is aggregated with word-level and sentence-level embedding to generate both visual contextual word and sentence representation. For the evaluation, we attached VICTR to the state-of-the-art models in text-to-image generation.VICTR is easily added to existing models and improves across both quantitative and qualitative aspects.",
}

@inproceedings{huang2020aligned,
  title={Aligned Dual Channel Graph Convolutional Network for Visual Question Answering},
  author={Huang, Qingbao and Wei, Jielong and Cai, Yi and Zheng, Changmeng and Chen, Junying and Leung, Ho-fung and Li, Qing},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7166--7176},
  year={2020}
}

@inproceedings{cho2014learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
}

@article{lu2016hierarchical,
  title={Hierarchical question-image co-attention for visual question answering},
  author={Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={289--297},
  year={2016}
}

@inproceedings{liu2019densely,
  title={Densely Connected Attention Flow for Visual Question Answering.},
  author={Liu, Fei and Liu, Jing and Fang, Zhiwei and Hong, Richang and Lu, Hanqing},
  booktitle={IJCAI},
  pages={869--875},
  year={2019}
}

@inproceedings{gao2019dynamic,
  title={Dynamic fusion with intra-and inter-modality attention flow for visual question answering},
  author={Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6639--6648},
  year={2019}
}

@article{kim2018bilinear,
  title={Bilinear attention networks},
  author={Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={1564--1574},
  year={2018}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{yu2019deep,
  title={Deep modular co-attention networks for visual question answering},
  author={Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6281--6290},
  year={2019}
}

@article{perez2017film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  journal={arXiv preprint arXiv:1709.07871},
  year={2017}
}

@inproceedings{yao2019graph,
  title={Graph convolutional networks for text classification},
  author={Yao, Liang and Mao, Chengsheng and Luo, Yuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7370--7377},
  year={2019}
}

@inproceedings{liu2020tensor,
  title={Tensor Graph Convolutional Networks for Text Classification.},
  author={Liu, Xien and You, Xinxin and Zhang, Xiao and Wu, Ji and Lv, Ping},
  booktitle={AAAI},
  pages={8409--8416},
  year={2020}
}

@inproceedings{andreas2016learning,
  title="Learning to Compose Neural Networks for Question Answering",
  author="Andreas, Jacob  and
    Rohrbach, Marcus  and
    Darrell, Trevor  and
    Klein, Dan",
  booktitle="Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month=jun,
  year="2016",
  address="San Diego, California",
  publisher="Association for Computational Linguistics",
  url="https://www.aclweb.org/anthology/N16-1181",
  doi="10.18653/v1/N16-1181",
  pages="1545--1554",
}

@article{tucker1966some,
  title={Some mathematical notes on three-mode factor analysis},
  author={Tucker, Ledyard R},
  journal={Psychometrika},
  volume={31},
  number={3},
  pages={279--311},
  year={1966},
  publisher={Springer}
}

@article{harshman1970foundations,
  title={Foundations of the PARAFAC procedure: Models and conditions for an" explanatory" multimodal factor analysis},
  author={Harshman, Richard A and others},
  year={1970},
  publisher={University of California at Los Angeles Los Angeles, CA}
}

@Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2018},
   url = {http://www.blender.org},
 }
 
 @inproceedings{johnson2015image,
  title={Image retrieval using scene graphs},
  author={Johnson, Justin and Krishna, Ranjay and Stark, Michael and Li, Li-Jia and Shamma, David and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3668--3678},
  year={2015}
}

@article{ren2016faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={6},
  pages={1137--1149},
  year={2016},
  publisher={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{agrawal2016analyzing,
  title={Analyzing the Behavior of Visual Question Answering Models},
  author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={1955--1960},
  year={2016}
}

@inproceedings{li2017scene,
author = {Li, Yikang and Ouyang, Wanli and Zhou, Bolei and Wang, Kun and Wang, Xiaogang},
title = {Scene Graph Generation From Objects, Phrases and Region Captions},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={1261--1270},
  year={2017}
}

@InProceedings{tang2019learning,
author = {Tang, Kaihua and Zhang, Hanwang and Wu, Baoyuan and Luo, Wenhan and Liu, Wei},
title = {Learning to Compose Dynamic Tree Structures for Visual Contexts},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6619--6628},
  year={2019}
}

@inproceedings{xu2017scene,
  title={Scene graph generation by iterative message passing},
  author={Xu, Danfei and Zhu, Yuke and Choy, Christopher B and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5410--5419},
  year={2017}
}

@inproceedings{hudson2019learning,
 author = {Hudson, Drew and Manning, Christopher D},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {5903--5916},
 publisher = {Curran Associates, Inc.},
 title = {Learning by Abstraction: The Neural State Machine},
 url = {https://proceedings.neurips.cc/paper/2019/file/c20a7ce2a627ba838cfbff082db35197-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{tan2019lxmert,
    title = "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers",
    author = "Tan, Hao  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1514",
    doi = "10.18653/v1/D19-1514",
    pages = "5100--5111",
}



@online{tan2019lxmertgithub,
  author = "Tan, Hao  and
      Bansal, Mohit",
  title = {LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  year = 2020,
  url = {https://github.com/airsplay/lxmert},
  urldate = {2020-12-28}
}

@article{guo2019bilinear,
  author    = {Dalu Guo and
               Chang Xu and
               Dacheng Tao},
  title     = {Graph Reasoning Networks for Visual Question Answering},
  journal   = {CoRR},
  volume    = {abs/1907.09815},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.09815},
  archivePrefix = {arXiv},
  eprint    = {1907.09815},
  timestamp = {Fri, 15 Nov 2019 17:16:02 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-09815.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@online{gqachallenge,
  author = {Hudson, Drew and Manning, Christopher D},
  title = {GQA Real-World Visual Reasoning Challenge},
  year = 2020,
  publisher = {EvalAI},
  url = {https://eval.ai/web/challenges/challenge-page/225/leaderboard/733},
  urldate = {2020-12-28}
}

@article{yangtrrnet,
  title={TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering},
  author={Yang, Xiaofeng and Lin, Guosheng and Lv, Fengmao and Liu, Fayao}
}

@inproceedings{kim2020hypergraph,
  title={Hypergraph Attention Networks for Multimodal Learning},
  author={Kim, Eun-Sol and Kang, Woo Young and On, Kyoung-Woon and Heo, Yu-Jung and Zhang, Byoung-Tak},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14581--14590},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{de2014universal,
  title={Universal Stanford dependencies: A cross-linguistic typology.},
  author={De Marneffe, Marie-Catherine and Dozat, Timothy and Silveira, Natalia and Haverinen, Katri and Ginter, Filip and Nivre, Joakim and Manning, Christopher D},
  booktitle={LREC},
  volume={14},
  pages={4585--4592},
  year={2014}
}

@inproceedings{ben2017mutan,
  title={Mutan: Multimodal tucker fusion for visual question answering},
  author={Ben-Younes, Hedi and Cadene, R{\'e}mi and Cord, Matthieu and Thome, Nicolas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2612--2620},
  year={2017}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@online{github-mac-reimplementation,
  author = "Cristobal Eyzaguirre",
  title = {mac-network-pytorch},
  year = 2019,
  url = {https://github.com/ceyzaguirre4/mac-network-pytorch},
  urldate = {2020-12-29}
}

@online{github-mac-official,
  author = {Hudson, Drew and Manning, Christopher D},
  title = {Compositional Attention Networks for Real-World Reasoning},
  year = 2019,
  url = {https://github.com/stanfordnlp/mac-network},
  urldate = {2020-12-29}
}



